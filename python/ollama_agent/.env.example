# Ollama Configuration
# Copy this file to .env and fill in your values (optional - defaults are provided)
# Based on agent-framework reference: https://github.com/microsoft/agent-framework

# OLLAMA_HOST is used by OllamaChatClient (defaults to http://localhost:11434)
OLLAMA_HOST=http://localhost:11434

# OLLAMA_CHAT_MODEL_ID is used by OllamaChatClient to specify the model
# For function calling support, try: mistral, qwen2.5:8b
OLLAMA_CHAT_MODEL_ID=ministral-3

# Optional: Number of iterations for performance testing (default: 1000)
# ITERATIONS=1000

